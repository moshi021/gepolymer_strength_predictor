# -*- coding: utf-8 -*-
"""Geopolymer Strength Predictor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/178gMDVXW_7UgIn7yEr10-K6xwCGIfc1e
"""

import streamlit as st
import pandas as pd
import xgboost as xgb
from PIL import Image
import shap
import matplotlib.pyplot as plt

# Set page config
st.set_page_config(
    page_title="Geopolymer Strength Predictor",
    layout="wide"
)

# --- Apply custom CSS for white background and black text ---
# This forces a light-theme look, regardless of system settings.
st.markdown("""
<style>
    /* Main app background */
    [data-testid="stAppViewContainer"] {
        background-color: #FFFFFF;
    }

    /* All text in the main app area */
    [data-testid="stAppViewContainer"] *,
    [data-testid="stHeader"] * {
        color: #000000;
    }

    /* Explicitly set headers */
    h1, h2, h3, h4, h5, h6 {
        color: #000000;
    }

    /* --- FIX for number inputs --- */
    /* Target the text inside the number input box */
    [data-testid="stNumberInput"] input {
        color: #FFFFFF; /* Make the text white */
    }

    /* Target the + and - buttons (SVGs) inside the number input */
    [data-testid="stNumberInput"] button svg {
        fill: #FFFFFF; /* Make the + and - icons white */
    }
</style>
""", unsafe_allow_html=True)


# --- Model Training ---
# This section replicates the core logic from your Jupyter notebook.

@st.cache_data
def load_data(path):
    """Loads and cleans the data from the CSV file."""
    try:
        df = pd.read_csv(path)
    except FileNotFoundError:
        st.error(f"Error: The file '{path}' was not found. Please make sure it's in the same directory as this app.")
        return None

    # Replicating the notebook's df.dropna() to get a clean dataset
    # This ensures we only train on complete records
    df_cleaned = df.dropna()
    return df_cleaned

@st.cache_resource
def train_model(df):
    """Trains the XGBoost model on the provided dataframe."""
    # Define features (X) and target (y) based on the notebook
    try:
        X = df.drop(columns=['Compressive Strength (MPa)', 'Total GHG emission', 'Total Cost(USD)'])
        y = df['Compressive Strength (MPa)']
    except KeyError as e:
        st.error(f"DataError: Missing expected column {e}. Please check your CSV file.")
        return None, None

    # Initialize and train the model
    model = xgb.XGBRegressor(random_state=42)
    model.fit(X, y)

    # Return the trained model, features, and target
    return model, X, y

@st.cache_data
def get_shap_plot(_model, _X):
    """Generates and returns a matplotlib figure of the SHAP summary plot."""
    # Note: SHAP calculations can be slow on large datasets
    explainer = shap.Explainer(_model)
    shap_values = explainer(_X)

    # Create a matplotlib figure
    fig, ax = plt.subplots()
    shap.summary_plot(shap_values, _X, show=False)
    plt.tight_layout() # Adjust layout to prevent cropping
    return fig

# --- Main Application ---

st.title("Geopolymer Compressive Strength Predictor")
st.markdown("This app predicts the compressive strength of geopolymer materials based on your input parameters, build by Md. Mashiur Rahman")
st.markdown("### Model $R^2 = 95\%$")

# Load data and train the model
data = load_data('etai final.csv')

if data is not None:
    model, features_data, target_data = train_model(data)

    if model and features_data is not None:
        # --- User Inputs in Main Area ---
        st.subheader("Input Parameters")
        st.markdown("Adjust the values below to set the features for prediction.")

        # Create columns for a cleaner layout
        cols = st.columns(3)

        # Create a dictionary to hold the user's inputs
        user_inputs = {}

        # Dynamically create number inputs in columns
        for i, col_name in enumerate(features_data.columns):
            # Determine which column to place the input in
            current_col = cols[i % 3]

            # Use min, max, and mean from the training data to set slider defaults
            min_val = float(features_data[col_name].min())
            max_val = float(features_data[col_name].max())
            mean_val = float(features_data[col_name].mean())

            # Use st.number_input for better precision, especially for float values
            user_inputs[col_name] = current_col.number_input(
                label=col_name,
                min_value=min_val,
                max_value=max_val,
                value=mean_val,
                step=0.1  # A reasonable step for most inputs
            )

        # Convert user inputs into a DataFrame for prediction
        input_df = pd.DataFrame([user_inputs])

        # --- Display Inputs and Prediction ---

        # Display the user's selected parameters
        st.subheader("Your Input Parameters")
        st.dataframe(input_df)

        # Generate and display the prediction
        prediction = model.predict(input_df)

        st.subheader("Prediction")
        st.metric(
            label="Predicted Compressive Strength",
            value=f"{prediction[0]:.2f} MPa"
        )

        st.divider()

        # --- Model Performance Plots ---

        # Create two columns for the plots
        plot_col1, plot_col2 = st.columns(2)

        with plot_col1:
            # Scatter plot: Predicted vs. Actual
            st.subheader("Model Performance")
            st.markdown("Predicted vs. Actual values from the training data.")
            y_pred = model.predict(features_data)

            plot_data = pd.DataFrame({
                'Actual': target_data,
                'Predicted': y_pred
            })

            st.scatter_chart(plot_data, x='Actual', y='Predicted')

        with plot_col2:
            # SHAP Summary Plot
            st.subheader("SHAP Summary Plot")
            st.markdown("Feature impact on model output (from training data).")

            with st.spinner("Calculating SHAP values..."):
                # Generate and display the cached SHAP plot
                shap_fig = get_shap_plot(model, features_data)
                st.pyplot(shap_fig, bbox_inches='tight', use_container_width=True)

        # --- Add Footer/Credit ---
        st.divider()
        st.divider()
        st.markdown("Built by **Md. Mashiur Rahman** | [LinkedIn](https://www.linkedin.com/in/mashiur-rahman-ruet/) | [Email](2013021@student.ruet.ac.bd)")
    else:
        st.error("Model could not be trained. Please check your data and the console for errors.")
else:
    st.error("Data could not be loaded. The app cannot proceed.")